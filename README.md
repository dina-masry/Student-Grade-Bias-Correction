# Student-Grade-Bias-Correction
## Description
This repository contains a data cleaning and analysis project focused on identifying and mitigating bias within a student grading dataset. The goal is to ensure that grading models and data are fair and equitable, preventing biased outcomes based on sensitive attributes like gender, socioeconomic status, or other demographic factors.
By correcting for existing bias, this project aims to create a more reliable and just dataset for training machine learning models used in educational contexts.
## Features
 - Bias Identification: Analyze the raw dataset to detect and quantify existing biases.

 - Data Cleaning and Preprocessing: Implement robust techniques to clean, handle missing values, and prepare the data for analysis.

 - Bias Mitigation: Apply data de-biasing strategies to create a more balanced and fair dataset.

- Evaluation: Compare the original and de-biased datasets to demonstrate the effectiveness of the bias correction methods.

## Data Cleaning and Preprocessing

The initial phase of this project involved thorough data cleaning and preprocessing to ensure the dataset's quality and reliability. Key steps included:

 - Handling Duplicates: Identified and removed duplicate rows to ensure that each student entry is unique and does not unfairly skew the analysis or model training.

 - Managing Missing Data: Assessed the extent of missing values and implemented appropriate strategies, such as imputation (e.g., mean, median, or mode) or selective row/column removal, to maintain data integrity without introducing further bias.

- Addressing Inconsistent and Unusual Data: Performed rigorous checks to identify and correct inconsistent data formats, outliers, and unusual entries. This involved standardizing text fields, correcting data entry errors, and ensuring logical consistency across all features.
## Result:
- A clean dataset ready for modeling.

